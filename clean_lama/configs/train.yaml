# LaMa Training Configuration

model:
  ngf: 64  # Generator base filters
  n_downsampling: 3  # Number of downsampling layers
  n_blocks: 18  # Number of ResNet blocks
  ratio: 0.75  # Ratio for FFC blocks
  ndf: 64  # Discriminator base filters
  n_discriminator_layers: 3  # Number of discriminator layers

training:
  batch_size: 8
  epochs: 100
  lr: 0.0002
  beta1: 0.0
  beta2: 0.9
  lr_decay_steps: 1000
  lr_decay_rate: 0.1
  gan_mode: lsgan  # Options: lsgan, vanilla, hinge
  val_check_interval: 1.0
  early_stopping_patience: 10

losses:
  l1: 1.0
  perceptual: 10.0
  style: 250.0
  adversarial: 0.1

data:
  image_size: 512
  train_dir: ./data/train/images
  train_masks_dir: ./data/train/masks
  val_dir: ./data/val/images
  val_masks_dir: ./data/val/masks